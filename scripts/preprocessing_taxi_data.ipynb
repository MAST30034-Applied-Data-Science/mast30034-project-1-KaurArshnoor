{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve yellow taxi data from Oct-2018 to March-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following was modified from MAST30024 Tutorial 1\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "output_relative_dir = '../data/'\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    \n",
    "# now, for each type of data set we will need, we will create the paths\n",
    "for target_dir in ('tlc_data', 'tute_data'): # taxi_zones should already exist\n",
    "    if not os.path.exists(output_relative_dir + target_dir):\n",
    "        os.makedirs(output_relative_dir + target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following was modified from MAST30024 Tutorial 1\n",
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\"#year-month.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin month 10\n",
      "Completed month 10\n",
      "Begin month 11\n",
      "Completed month 11\n",
      "Begin month 12\n",
      "Completed month 12\n"
     ]
    }
   ],
   "source": [
    "# The following was modiefied from MAST30024 Tutorial 1\n",
    "# yellow taxi data for October, November, December 2018\n",
    "YEAR = '2018'\n",
    "MONTHS_2018 = range(10, 13)\n",
    "\n",
    "tlc_output_dir = output_relative_dir + 'raw/tlc_data'\n",
    "\n",
    "for month in MONTHS_2018:\n",
    "    # 0-fill i.e 1 -> 01, 2 -> 02, etc\n",
    "    month = str(month).zfill(2) \n",
    "    print(f\"Begin month {month}\")\n",
    "    \n",
    "    # generate url\n",
    "    url = f'{URL_TEMPLATE}{YEAR}-{month}.parquet'\n",
    "    # generate output location and filename\n",
    "    output_dir = f\"{tlc_output_dir}/{YEAR}-{month}.parquet\"\n",
    "    # download\n",
    "    urlretrieve(url, output_dir) \n",
    "    \n",
    "    print(f\"Completed month {month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin month 01\n",
      "Completed month 01\n",
      "Begin month 02\n",
      "Completed month 02\n",
      "Begin month 03\n",
      "Completed month 03\n"
     ]
    }
   ],
   "source": [
    "# The following was modiefied from MAST30024 Tutorial 1\n",
    "# yellow taxi data for January, February, March 2019\n",
    "YEAR = '2019'\n",
    "MONTHS_2019 = range(1, 4)\n",
    "\n",
    "tlc_output_dir = output_relative_dir + 'raw/tlc_data'\n",
    "\n",
    "for month in MONTHS_2019:\n",
    "    # 0-fill i.e 1 -> 01, 2 -> 02, etc\n",
    "    month = str(month).zfill(2) \n",
    "    print(f\"Begin month {month}\")\n",
    "    \n",
    "    # generate url\n",
    "    url = f'{URL_TEMPLATE}{YEAR}-{month}.parquet'\n",
    "    # generate output location and filename\n",
    "    output_dir = f\"{tlc_output_dir}/{YEAR}-{month}.parquet\"\n",
    "    # download\n",
    "    urlretrieve(url, output_dir) \n",
    "    \n",
    "    print(f\"Completed month {month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47798251"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of records for yellow taxis October-2018 to March-2019\n",
    "\n",
    "sdf_all = spark.read.parquet('../data/raw/tlc_data/')\n",
    "sdf_all.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process yellow taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: integer (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32737776"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter data and remove outliers - where passenger count <=0 and trip distance <=0 miles or >=246.9 miles\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "required_cols = ('tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', \n",
    "                 'RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'tip_amount', 'total_amount')\n",
    "processed_yellow_taxi_data = sdf_all.select(*required_cols).where(\n",
    "    (F.col('passenger_count') > 0) \n",
    "    & (F.col('trip_distance') > 0)\n",
    "    & (F.col('trip_distance') < 246.9)\n",
    "    & (F.col('PULocationID') < 264)\n",
    "    & (F.col('DOLocationID') < 264)\n",
    "    & (F.col('payment_type') == 1)\n",
    ")\n",
    "\n",
    "processed_yellow_taxi_data.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_154728/3799255084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  'RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'tip_amount', 'total_amount')\n\u001b[1;32m      4\u001b[0m sdf_all.select(*required_cols).where(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VendorID'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NA' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "required_cols = ('VendorID','tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', \n",
    "                 'RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'tip_amount', 'total_amount')\n",
    "sdf_all.select(*required_cols).where(\n",
    "    (F.col('VendorID') == NA)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert csv files to parquet file format\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/raw/oct.csv')\n",
    "df.to_parquet('../data/raw/oct.parquet')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
