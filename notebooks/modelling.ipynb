{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/21 20:53:45 WARN Utils: Your hostname, mast30034 resolves to a loopback address: 127.0.1.1; using 45.113.234.45 instead (on interface eth0)\n",
      "22/08/21 20:53:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/21 20:53:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/21 20:53:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/08/21 20:53:47 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/08/21 20:53:47 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/08/21 20:53:47 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/08/21 20:53:47 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/08/21 20:53:47 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName('MAST30034 Tutorial 3')\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get taxi_weather data for all months\n",
    "taxi_weather_data = spark.read.parquet('../data/curated/taxi_weather_data/final-2018-10.parquet')\n",
    "\n",
    "files = ['final-2018-11.parquet', 'final-2018-12.parquet', 'final-2019-01.parquet', \n",
    "         'final-2019-02.parquet', 'final-2019-03.parquet']\n",
    "\n",
    "for file in files:\n",
    "    taxi_weather_month = spark.read.parquet(f'../data/curated/taxi_weather_data/{file}')\n",
    "    # add each month taxi_weather_data to october dataframe\n",
    "    taxi_weather_data = taxi_weather_data.union(taxi_weather_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_date: date (nullable = true)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- pickup_day: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- average_temp: double (nullable = true)\n",
      " |-- average_dew_point: double (nullable = true)\n",
      " |-- average_wind_speed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_weather_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the data \n",
    "taxi_weather_data = taxi_weather_data.sample(withReplacement=None, fraction=0.02, seed=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model\n",
    "#### Using features:\n",
    "- 'passenger_count\n",
    "- 'trip_distance'\n",
    "- 'PULocationID'\n",
    "- 'RatecodeID'\n",
    "- 'average_temp' \n",
    "- 'average_dew_point'\n",
    "- 'average_wind_speed'\n",
    "- 'total_amount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:====================================================>  (148 + 6) / 154]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|PULocationID|PULocation_dummy|\n",
      "+------------+----------------+\n",
      "|         263|     (263,[],[])|\n",
      "|           1| (263,[1],[1.0])|\n",
      "|           2| (263,[2],[1.0])|\n",
      "|           3| (263,[3],[1.0])|\n",
      "|           4| (263,[4],[1.0])|\n",
      "|           5| (263,[5],[1.0])|\n",
      "|           7| (263,[7],[1.0])|\n",
      "|           8| (263,[8],[1.0])|\n",
      "|           9| (263,[9],[1.0])|\n",
      "|          10|(263,[10],[1.0])|\n",
      "|          11|(263,[11],[1.0])|\n",
      "|          12|(263,[12],[1.0])|\n",
      "|          13|(263,[13],[1.0])|\n",
      "|          14|(263,[14],[1.0])|\n",
      "|          15|(263,[15],[1.0])|\n",
      "|          16|(263,[16],[1.0])|\n",
      "|          17|(263,[17],[1.0])|\n",
      "|          18|(263,[18],[1.0])|\n",
      "|          19|(263,[19],[1.0])|\n",
      "|          20|(263,[20],[1.0])|\n",
      "+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# one hot encode categorical data - PUlocation, DOlocation before linear regression\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# one hot encoder PULocationID\n",
    "onehot_pu = OneHotEncoder(inputCols=['PULocationID'],outputCols=['PULocation_dummy'])\n",
    "\n",
    "# apply the one hot encoder to the taxi_weather data\n",
    "taxi_weather_data2 = onehot_pu.fit(taxi_weather_data).transform(taxi_weather_data)\n",
    "\n",
    "# display results\n",
    "taxi_weather_data2.select('PULocationID', 'PULocation_dummy').distinct().sort('PULocation_dummy').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+----------+----------------+\n",
      "|PULocationID|PULocation_dummy|RatecodeID|RatecodeID_dummy|\n",
      "+------------+----------------+----------+----------------+\n",
      "|         263|     (263,[],[])|       3.0|   (5,[3],[1.0])|\n",
      "|         263|     (263,[],[])|       5.0|       (5,[],[])|\n",
      "|         263|     (263,[],[])|       2.0|   (5,[2],[1.0])|\n",
      "|         263|     (263,[],[])|       1.0|   (5,[1],[1.0])|\n",
      "|           1| (263,[1],[1.0])|       3.0|   (5,[3],[1.0])|\n",
      "|           1| (263,[1],[1.0])|       5.0|       (5,[],[])|\n",
      "|           2| (263,[2],[1.0])|       1.0|   (5,[1],[1.0])|\n",
      "|           3| (263,[3],[1.0])|       5.0|       (5,[],[])|\n",
      "|           3| (263,[3],[1.0])|       1.0|   (5,[1],[1.0])|\n",
      "|           4| (263,[4],[1.0])|       3.0|   (5,[3],[1.0])|\n",
      "|           4| (263,[4],[1.0])|       1.0|   (5,[1],[1.0])|\n",
      "|           4| (263,[4],[1.0])|       5.0|       (5,[],[])|\n",
      "|           4| (263,[4],[1.0])|       2.0|   (5,[2],[1.0])|\n",
      "|           5| (263,[5],[1.0])|       1.0|   (5,[1],[1.0])|\n",
      "|           7| (263,[7],[1.0])|       5.0|       (5,[],[])|\n",
      "|           7| (263,[7],[1.0])|       1.0|   (5,[1],[1.0])|\n",
      "|           7| (263,[7],[1.0])|       2.0|   (5,[2],[1.0])|\n",
      "|           8| (263,[8],[1.0])|       2.0|   (5,[2],[1.0])|\n",
      "|           8| (263,[8],[1.0])|       1.0|   (5,[1],[1.0])|\n",
      "|           9| (263,[9],[1.0])|       1.0|   (5,[1],[1.0])|\n",
      "+------------+----------------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:====================================================> (151 + 3) / 154]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# one hot encoder DOLocationID\n",
    "onehot_rate = OneHotEncoder(inputCols=['RatecodeID'], outputCols=['RatecodeID_dummy'])\n",
    "\n",
    "# apply the one hot encoder to the taxi_weather data\n",
    "taxi_weather_onehot = onehot_rate.fit(taxi_weather_data2).transform(taxi_weather_data2)\n",
    "\n",
    "# display results\n",
    "taxi_weather_onehot.select('PULocationID', 'PULocation_dummy','RatecodeID', 'RatecodeID_dummy').distinct().sort('PULocation_dummy').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from MAST30034: Tutorial 3\n",
    "# VectorAssembler creates new vectors from existing columns\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = 'features'\n",
    "input_cols = ['trip_distance', 'PULocationID', 'RatecodeID', 'average_temp', \n",
    "              'average_dew_point', 'average_wind_speed', 'total_amount']\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    # which column to combine\n",
    "    inputCols=input_cols, \n",
    "    # How should the combined columns be named\n",
    "    outputCol=features\n",
    ")\n",
    "\n",
    "taxi_weather_final = assembler.transform(taxi_weather_onehot.dropna('any'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing data\n",
    "train_df, test_df = taxi_weather_final.randomSplit([0.7, 0.3], seed = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/21 20:54:01 WARN Instrumentation: [0b84bbce] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for linear regression model: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2809785540175938"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# train linear regression model on training taxi_weather data\n",
    "lm = LinearRegression(featuresCol='features', labelCol='tip_amount').fit(train_df)\n",
    "\n",
    "# Create predictions for the test data\n",
    "predictions = lm.transform(test_df)\n",
    "\n",
    "# Calculate the RMSE\n",
    "print(\"RMSE for linear regression model: \")\n",
    "RegressionEvaluator(labelCol='tip_amount', metricName='rmse').evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.135099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>-0.353345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PULocationID</th>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RatecodeID</th>\n",
       "      <td>-0.837902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_temp</th>\n",
       "      <td>-0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_dew_point</th>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_wind_speed</th>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount</th>\n",
       "      <td>0.249109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coefficient\n",
       "intercept              0.135099\n",
       "trip_distance         -0.353345\n",
       "PULocationID           0.000211\n",
       "RatecodeID            -0.837902\n",
       "average_temp          -0.000619\n",
       "average_dew_point      0.000596\n",
       "average_wind_speed     0.000549\n",
       "total_amount           0.249109"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access coefficients\n",
    "pd.DataFrame(\n",
    "    data=[lm.intercept] + list(lm.coefficients),\n",
    "    index=['intercept'] + input_cols,\n",
    "    columns=['coefficient']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for decision tree model: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.345640016195891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "# train decision tree model on training taxi_weather data\n",
    "dt_model = DecisionTreeRegressor(featuresCol ='features', labelCol = 'tip_amount').fit(train_df)\n",
    "\n",
    "# Create predictions for the test data\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "\n",
    "# Calculate the RMSE\n",
    "print('RMSE for decision tree model: ')\n",
    "RegressionEvaluator(labelCol='tip_amount', metricName=\"rmse\").evaluate(dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
